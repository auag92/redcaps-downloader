{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87f8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import click\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import plotly.express as px\n",
    "import multiprocessing as mp\n",
    "from calendar import Calendar\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from toolz.curried import compose, pipe, curry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d23a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redcaps\n",
    "import redcaps._color_print as cprint\n",
    "from redcaps.downloaders import (\n",
    "    ImageDownloader,\n",
    "    RedditIdDownloader,\n",
    "    RedditInfoDownloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6daa69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _image_worker(args):\n",
    "    r\"\"\"Helper method for parallelizing image downloads.\"\"\"\n",
    "    image_urls, image_uid, downloader_fn = args\n",
    "    download_status = []\n",
    "    for ix, image_url in enumerate(image_urls):\n",
    "        save_to = f\"datasets/catalog/{image_uid}/{ix}.png\"\n",
    "        download_status.append(downloader_fn(image_url, save_to=save_to))\n",
    "\n",
    "    # Sleep for 2 seconds for Imgur, and 0.1 seconds for Reddit and Flickr.\n",
    "    # This takes care of all request rate limits.\n",
    "    if \"imgur\" in image_url:\n",
    "        time.sleep(2.0)\n",
    "    else:\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    return download_status\n",
    "\n",
    "@curry\n",
    "def image_downloader(url: str, save_to: str, longer_resize: int = 512) -> bool:\n",
    "    r\"\"\"\n",
    "    Download image from ``url`` and save it to ``save_to``.\n",
    "\n",
    "    Args:\n",
    "        url: Image URL to download from.\n",
    "        save_to: Local path to save the downloaded image.\n",
    "\n",
    "    Returns:\n",
    "        Boolean variable indicating whether the download was successful\n",
    "        (``True``) or not (``False``).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 'response.content' will have our image (as bytes) if successful.\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if image was downloaded (response must be 200). One exception:\n",
    "        # Imgur gives response 200 with \"removed.png\" image if not found.\n",
    "#         urllib.request.urlretrieve(\"http://www.gunnerkrigg.com//comics/00000001.jpg\", \"00000001.jpg\")\n",
    "        if response.status_code != 200 or \"removed.png\" in response.url:\n",
    "            return False\n",
    "\n",
    "        # Write image to disk if it was downloaded successfully.\n",
    "        pil_image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "        # Resize image to longest max size while preserving aspect ratio if\n",
    "        # longest max size is provided (not -1), and image is bigger.\n",
    "        if longer_resize > 0:\n",
    "            image_width, image_height = pil_image.size\n",
    "\n",
    "            scale = longer_resize / float(max(image_width, image_height))\n",
    "\n",
    "            if scale != 1.0:\n",
    "                new_width, new_height = tuple(\n",
    "                    int(round(d * scale)) for d in (image_width, image_height)\n",
    "                )\n",
    "                pil_image = pil_image.resize((new_width, new_height))\n",
    "\n",
    "        # Save the downloaded image to disk.\n",
    "        os.makedirs(os.path.dirname(save_to), exist_ok=True)\n",
    "        pil_image.save(save_to)\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return False   \n",
    "    \n",
    "    \n",
    "def download_imgs(\n",
    "    annotations_list: str,\n",
    "    resize: int,\n",
    "    workers: int,\n",
    "):\n",
    "\n",
    "    # Parallelize image downloads.\n",
    "    with mp.Pool(processes=workers) as p:\n",
    "\n",
    "        worker_args: List[Tuple] = []\n",
    "        for ann in annotations_list:\n",
    "            \n",
    "            worker_args.append((ann[\"image_links\"], ann[\"id\"], image_downloader(longer_resize=resize)))\n",
    "        download_status = []\n",
    "\n",
    "        with tqdm(total=len(worker_args), desc=\"Downloading Images\") as pbar:\n",
    "            for _status in p.imap(_image_worker, worker_args):\n",
    "                download_status.append(_status)\n",
    "                pbar.update()\n",
    "\n",
    "\n",
    "# uid = annotations_list[0][\"id\"]\n",
    "# for ix, url in enumerate(annotations_list[0]['image_links']):\n",
    "#     save_to = f\"datasets/catalog/{uid}/{ix}.png\"\n",
    "#     output = image_downloader(url=url, save_to=save_to, longer_resize=resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26fdc4",
   "metadata": {},
   "source": [
    "#### The following code snipped was used to generate and save (locally) a csv file containing \"Scrapped Atributes\" of 10000 ready to send annotations.\n",
    "\n",
    "<code>\n",
    "select SCRAPED_ATTRIBUTES \n",
    "from PUBLIC.PRODUCTVARIANTS pv\n",
    "where STATUS = 'ready_to_send'\n",
    "limit 10000\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2a37af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/catalog/result_10000.csv\")\n",
    "annotations_list = [json.loads(row[1].item()) for row in df.iterrows()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46794aac",
   "metadata": {},
   "source": [
    "The following snippet can be used to download images associated with one of the annotations in the above created list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "011b1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = annotations_list[0]\n",
    "# args = (ann[\"image_links\"], ann[\"id\"], image_downloader(longer_resize=resize))\n",
    "# output = _image_worker(args)\n",
    "# print(\"{}, Broken link fraction: {:1.3f}\".format(ix, 1.-(sum(output)/len(output))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccac699",
   "metadata": {},
   "source": [
    "The following snippet can be used to iterate over all items in the annotations list and save the images locally in the \"dataset/catalog\" folder, with subfolders to distinguish between items with different ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2665036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Broken link fraction: 0.000\n",
      "1, Broken link fraction: 0.000\n",
      "2, Broken link fraction: 0.000\n",
      "3, Broken link fraction: 0.667\n",
      "4, Broken link fraction: 0.000\n",
      "5, Broken link fraction: 0.000\n",
      "6, Broken link fraction: 0.000\n",
      "7, Broken link fraction: 0.000\n",
      "8, Broken link fraction: 0.000\n",
      "9, Broken link fraction: 0.000\n"
     ]
    }
   ],
   "source": [
    "resize = 512\n",
    "for ix, ann in enumerate(annotations_list[10:20]):\n",
    "    args = (ann[\"image_links\"], ann[\"id\"], image_downloader(longer_resize=resize))\n",
    "    output = _image_worker(args)\n",
    "    print(\"{}, Broken link fraction: {:1.3f}\".format(ix, 1.-(sum(output)/len(output))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_imgs(annotations_list[20:30], resize=512, workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
